{"cells":[{"cell_type":"code","execution_count":6,"id":"t7O_2_dM_Cn2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1160,"status":"ok","timestamp":1751541536953,"user":{"displayName":"Sebastián Ignacio García Péndola","userId":"08175071328414149400"},"user_tz":240},"id":"t7O_2_dM_Cn2","outputId":"7e42f24d-798d-4559-d7f4-5eb317979ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"id":"dse_03ED9FWW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dse_03ED9FWW","outputId":"0fab91f0-463d-4b3b-8f56-977fa9f85597"},"outputs":[{"output_type":"stream","name":"stdout","text":["Usando dispositivo: cpu\n","\n","--- Conteo de valores para diabetes (Original antes de SMOTE): ---\n","diabetes\n","0    8500\n","1    8500\n","Name: count, dtype: int64\n","Iniciando preprocesamiento...\n","Preprocesado diabetes con One-Hot Encoding. Shape: (17000, 2)\n","3\n","Preprocesado gender con One-Hot Encoding. Shape: (17000, 3)\n","Preprocesado age con log1p + MinMaxScaler. Shape: (17000, 1)\n","Preprocesado bmi con log1p + MinMaxScaler. Shape: (17000, 1)\n","Preprocesado blood_glucose_level con log1p + MinMaxScaler. Shape: (17000, 1)\n","Preprocesado hypertension con MinMaxScaler. Shape: (17000, 1)\n","Preprocesado heart_disease con MinMaxScaler. Shape: (17000, 1)\n","Preprocesado smoking_history con MinMaxScaler. Shape: (17000, 1)\n","Preprocesado HbA1c_level con MinMaxScaler. Shape: (17000, 1)\n","Forma final de los datos procesados (X_train_processed_np): (17000, 12)\n","\n","--- Arquitectura del Generador (PyTorch) ---\n","Generator(\n","  (model): Sequential(\n","    (0): Linear(in_features=100, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Dropout(p=0.4, inplace=False)\n","    (3): BatchNorm1d(512, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=512, out_features=1024, bias=True)\n","    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (6): Dropout(p=0.3, inplace=False)\n","    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n","    (8): Linear(in_features=1024, out_features=2048, bias=True)\n","    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (10): Dropout(p=0.2, inplace=False)\n","    (11): BatchNorm1d(2048, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n","    (12): Linear(in_features=2048, out_features=4096, bias=True)\n","    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (14): Dropout(p=0.1, inplace=False)\n","    (15): BatchNorm1d(4096, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n","    (16): Linear(in_features=4096, out_features=12, bias=True)\n","    (17): Sigmoid()\n","  )\n",")\n","\n","--- Arquitectura del Discriminador (PyTorch) ---\n","Discriminator(\n","  (model): Sequential(\n","    (0): Linear(in_features=12, out_features=1024, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Linear(in_features=1024, out_features=512, bias=True)\n","    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (4): Dropout(p=0.3, inplace=False)\n","    (5): Linear(in_features=512, out_features=1, bias=True)\n","    (6): Sigmoid()\n","  )\n",")\n","\n","Iniciando entrenamiento de la GAN con PyTorch...\n","1/600 [D loss: 0.7017] [G loss: 0.6877]\n","2/600 [D loss: 0.6808] [G loss: 0.7078]\n","3/600 [D loss: 0.6955] [G loss: 0.6956]\n","4/600 [D loss: 0.6974] [G loss: 0.6766]\n","5/600 [D loss: 0.6940] [G loss: 0.6967]\n","6/600 [D loss: 0.6956] [G loss: 0.6879]\n","7/600 [D loss: 0.6854] [G loss: 0.7140]\n","8/600 [D loss: 0.6923] [G loss: 0.7035]\n","9/600 [D loss: 0.6922] [G loss: 0.6883]\n","10/600 [D loss: 0.6932] [G loss: 0.6936]\n","11/600 [D loss: 0.6945] [G loss: 0.6898]\n","12/600 [D loss: 0.6949] [G loss: 0.6926]\n","13/600 [D loss: 0.6916] [G loss: 0.6944]\n","14/600 [D loss: 0.6922] [G loss: 0.6882]\n","15/600 [D loss: 0.6976] [G loss: 0.6905]\n","16/600 [D loss: 0.6910] [G loss: 0.6965]\n","17/600 [D loss: 0.6933] [G loss: 0.6936]\n","18/600 [D loss: 0.6927] [G loss: 0.6962]\n","19/600 [D loss: 0.6934] [G loss: 0.6905]\n","20/600 [D loss: 0.6973] [G loss: 0.6996]\n","21/600 [D loss: 0.7122] [G loss: 0.6640]\n","22/600 [D loss: 0.7023] [G loss: 0.6709]\n","23/600 [D loss: 0.6947] [G loss: 0.6895]\n","24/600 [D loss: 0.6907] [G loss: 0.6885]\n","25/600 [D loss: 0.6966] [G loss: 0.6850]\n","26/600 [D loss: 0.6939] [G loss: 0.6995]\n","27/600 [D loss: 0.6948] [G loss: 0.6901]\n","28/600 [D loss: 0.6925] [G loss: 0.6906]\n","29/600 [D loss: 0.6969] [G loss: 0.6947]\n","30/600 [D loss: 0.6945] [G loss: 0.6885]\n","31/600 [D loss: 0.6933] [G loss: 0.6881]\n","32/600 [D loss: 0.6942] [G loss: 0.7055]\n","33/600 [D loss: 0.6945] [G loss: 0.6919]\n","34/600 [D loss: 0.6898] [G loss: 0.6914]\n","35/600 [D loss: 0.6904] [G loss: 0.6824]\n","36/600 [D loss: 0.6870] [G loss: 0.7024]\n","37/600 [D loss: 0.6961] [G loss: 0.6862]\n","38/600 [D loss: 0.6920] [G loss: 0.6854]\n","39/600 [D loss: 0.6926] [G loss: 0.6950]\n","40/600 [D loss: 0.6916] [G loss: 0.6870]\n","41/600 [D loss: 0.6859] [G loss: 0.6989]\n","42/600 [D loss: 0.6909] [G loss: 0.6897]\n","43/600 [D loss: 0.6894] [G loss: 0.6962]\n","44/600 [D loss: 0.6939] [G loss: 0.6947]\n","45/600 [D loss: 0.6988] [G loss: 0.6835]\n","46/600 [D loss: 0.6832] [G loss: 0.6951]\n","47/600 [D loss: 0.6957] [G loss: 0.6914]\n","48/600 [D loss: 0.6825] [G loss: 0.6942]\n","49/600 [D loss: 0.6909] [G loss: 0.6906]\n","50/600 [D loss: 0.6947] [G loss: 0.6868]\n","51/600 [D loss: 0.6982] [G loss: 0.6778]\n","52/600 [D loss: 0.6938] [G loss: 0.6916]\n","53/600 [D loss: 0.6880] [G loss: 0.6981]\n","54/600 [D loss: 0.6939] [G loss: 0.6938]\n","55/600 [D loss: 0.6959] [G loss: 0.6879]\n","56/600 [D loss: 0.6978] [G loss: 0.6809]\n","57/600 [D loss: 0.6922] [G loss: 0.6921]\n","58/600 [D loss: 0.6934] [G loss: 0.6953]\n","59/600 [D loss: 0.6827] [G loss: 0.6953]\n","60/600 [D loss: 0.6951] [G loss: 0.6923]\n","61/600 [D loss: 0.6933] [G loss: 0.6969]\n","62/600 [D loss: 0.6938] [G loss: 0.6958]\n","63/600 [D loss: 0.6898] [G loss: 0.6978]\n","64/600 [D loss: 0.6980] [G loss: 0.6925]\n","65/600 [D loss: 0.6955] [G loss: 0.6934]\n","66/600 [D loss: 0.6942] [G loss: 0.6866]\n","67/600 [D loss: 0.6865] [G loss: 0.7037]\n","68/600 [D loss: 0.6801] [G loss: 0.7113]\n","69/600 [D loss: 0.6757] [G loss: 0.7473]\n","70/600 [D loss: 0.6911] [G loss: 0.6916]\n","71/600 [D loss: 0.6932] [G loss: 0.6905]\n","72/600 [D loss: 0.6917] [G loss: 0.6888]\n","73/600 [D loss: 0.6937] [G loss: 0.6915]\n","74/600 [D loss: 0.6934] [G loss: 0.6926]\n","75/600 [D loss: 0.6923] [G loss: 0.6898]\n","76/600 [D loss: 0.6944] [G loss: 0.6925]\n","77/600 [D loss: 0.6911] [G loss: 0.6877]\n","78/600 [D loss: 0.6951] [G loss: 0.7065]\n","79/600 [D loss: 0.6921] [G loss: 0.6972]\n","80/600 [D loss: 0.6964] [G loss: 0.6844]\n","81/600 [D loss: 0.6892] [G loss: 0.6905]\n","82/600 [D loss: 0.6988] [G loss: 0.6899]\n","83/600 [D loss: 0.6919] [G loss: 0.6932]\n","84/600 [D loss: 0.6954] [G loss: 0.6938]\n","85/600 [D loss: 0.6919] [G loss: 0.6874]\n","86/600 [D loss: 0.6978] [G loss: 0.7013]\n","87/600 [D loss: 0.6945] [G loss: 0.6841]\n","88/600 [D loss: 0.6921] [G loss: 0.6911]\n","89/600 [D loss: 0.6917] [G loss: 0.6972]\n","90/600 [D loss: 0.6932] [G loss: 0.7001]\n","91/600 [D loss: 0.6962] [G loss: 0.6953]\n","92/600 [D loss: 0.6962] [G loss: 0.6878]\n","93/600 [D loss: 0.6950] [G loss: 0.6876]\n","94/600 [D loss: 0.6919] [G loss: 0.6966]\n","95/600 [D loss: 0.6925] [G loss: 0.7020]\n","96/600 [D loss: 0.6901] [G loss: 0.6907]\n","97/600 [D loss: 0.6882] [G loss: 0.7076]\n","98/600 [D loss: 0.6922] [G loss: 0.6955]\n","99/600 [D loss: 0.6949] [G loss: 0.6915]\n","100/600 [D loss: 0.6947] [G loss: 0.6961]\n","101/600 [D loss: 0.6914] [G loss: 0.6958]\n","102/600 [D loss: 0.6962] [G loss: 0.6903]\n","103/600 [D loss: 0.6929] [G loss: 0.7060]\n","104/600 [D loss: 0.6904] [G loss: 0.6976]\n","105/600 [D loss: 0.6931] [G loss: 0.6924]\n","106/600 [D loss: 0.6946] [G loss: 0.6940]\n","107/600 [D loss: 0.6961] [G loss: 0.6858]\n","108/600 [D loss: 0.6912] [G loss: 0.6890]\n","109/600 [D loss: 0.6919] [G loss: 0.7032]\n","110/600 [D loss: 0.6909] [G loss: 0.6846]\n","111/600 [D loss: 0.6904] [G loss: 0.7083]\n","112/600 [D loss: 0.6920] [G loss: 0.7049]\n","113/600 [D loss: 0.6955] [G loss: 0.6815]\n","114/600 [D loss: 0.6863] [G loss: 0.6961]\n","115/600 [D loss: 0.6825] [G loss: 0.7098]\n","116/600 [D loss: 0.6916] [G loss: 0.7210]\n","117/600 [D loss: 0.6890] [G loss: 0.7219]\n","118/600 [D loss: 0.6857] [G loss: 0.7243]\n","119/600 [D loss: 0.6636] [G loss: 0.7276]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.preprocessing import MinMaxScaler\n","# from sklearn.model_selection import train_test_split # No se usa directamente para GAN\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","# from torch.utils.data import DataLoader, TensorDataset # No se usará DataLoader para este ejemplo simple\n","\n","# --- Importar SMOTE ---\n","from imblearn.over_sampling import SMOTE # Importa SMOTE\n","\n","# --- 0. Parámetros de la GAN y del Entrenamiento ---\n","LATENT_DIM = 100\n","EPOCHS = 600 # Puede necesitar muchas más (ej. 10000-50000+) y ajustes\n","BATCH_SIZE = 64\n","SAMPLE_INTERVAL = 1 # Cada cuántas épocas guardar una muestra de datos generados\n","LEARNING_RATE_G = 0.0002\n","LEARNING_RATE_D = 0.00001\n","BETA1 = 0.5 # Parámetro de Adam\n","\n","iteration = 1\n","generator_path = \"/content/gdrive/My Drive/ResultCSV/Binary/generator_gan_pytorch.pth\"\n","discriminator_path = \"/content/gdrive/My Drive/ResultCSV/Binary/discriminator_gan_pytorch.pth\"\n","\n","# Configurar dispositivo (GPU si está disponible)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Usando dispositivo: {device}\")\n","\n","# --- 1. Cargar el archivo CSV original ---\n","input_file = '/content/gdrive/My Drive/Datasets/dataset.csv'\n","data = pd.read_csv(input_file)\n","data['gender'] = data['gender'].astype(str).str.strip().str.upper()\n","\n","# --- Verify unique values and NaNs after stripping and mapping ---\n","# print(\"Unique values in 'Diabetes_012' after stripping and mapping:\")\n","# print(data['gender'].unique())\n","# print(\"NaN values in 'Diabetes_012' after stripping and mapping:\")\n","# print(data['gender'].isnull().sum())\n","\n","# Mapear valores de 'Gender' a numéricos y luego aplicar One-Hot Encoding si es necesario\n","# Para 'Gender', puedes mapear 'F' a 0 y 'M' a 1.\n","data['gender'] = data['gender'].map({'FEMALE': 0, 'MALE': 1, 'OTHER': 2})\n","\n","# Mapear 'smoking_history' a valores numéricos si no lo están ya\n","# Asumiendo 'N'=0, 'P'=1, 'Y'=2\n","smoking_mapping = {'never': 0, 'No Info':1, 'current': 2, 'ever': 3, 'former':4, 'not current': 5}\n","data['smoking_history'] = data['smoking_history'].map(smoking_mapping)\n","\n","class_0 = data[data['diabetes'] == 0].sample(n=8500, random_state=42)\n","class_1 = data[data['diabetes'] == 1].sample(n=8500, random_state=42)\n","data_df = pd.concat([class_0, class_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n","original_columns = data.columns.tolist()\n","\n","# --- Verificar el conteo de clases ---\n","print(\"\\n--- Conteo de valores para diabetes (Original antes de SMOTE): ---\")\n","print(data_df['diabetes'].value_counts().sort_index())\n","\n","# --- 3. Preprocesamiento ---\n","print(\"Iniciando preprocesamiento...\")\n","processed_data_parts = []\n","scalers_dict = {}\n","column_info_for_generator_output = []\n","\n","special_cols_log_scale = ['age', 'bmi', 'blood_glucose_level']\n","diabetes_col = 'diabetes'\n","gender_col = 'gender' # Nueva columna categórica\n","\n","# A. diabetes (One-Hot Encoding)\n","#    Para PyTorch, no necesitamos to_categorical de Keras, podemos hacerlo con numpy\n","num_classes_diabetes = data_df[diabetes_col].nunique() # Obtener el número de clases dinámicamente\n","diabetes_one_hot = np.eye(num_classes_diabetes)[data_df[diabetes_col].astype(int)]\n","processed_data_parts.append(diabetes_one_hot)\n","column_info_for_generator_output.append({'name': diabetes_col, 'type': 'one_hot', 'num_classes': num_classes_diabetes})\n","print(f\"Preprocesado {diabetes_col} con One-Hot Encoding. Shape: {diabetes_one_hot.shape}\")\n","\n","# B. Gender (One-Hot Encoding)\n","num_classes_gender = data_df[gender_col].nunique() # Debería ser 2 (M/F)\n","print(num_classes_gender)\n","gender_one_hot = np.eye(num_classes_gender)[data_df[gender_col].astype(int)]\n","processed_data_parts.append(gender_one_hot)\n","column_info_for_generator_output.append({'name': gender_col, 'type': 'one_hot', 'num_classes': num_classes_gender})\n","print(f\"Preprocesado {gender_col} con One-Hot Encoding. Shape: {gender_one_hot.shape}\")\n","\n","# C. Columnas con log1p + MinMaxScaler\n","for col_name in special_cols_log_scale:\n","    original_values = data_df[col_name].values.reshape(-1, 1)\n","    log_transformed_values = np.log1p(original_values)\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    scaled_values = scaler.fit_transform(log_transformed_values)\n","    processed_data_parts.append(scaled_values)\n","    scalers_dict[col_name] = {'scaler': scaler, 'log_applied': True, 'original_min': original_values.min(), 'original_max': original_values.max()}\n","    column_info_for_generator_output.append({'name': col_name, 'type': 'scaled_continuous_sigmoid'})\n","    print(f\"Preprocesado {col_name} con log1p + MinMaxScaler. Shape: {scaled_values.shape}\")\n","\n","# D. Otras columnas (MinMaxScaler para [0,1])\n","\n","other_cols = [col for col in original_columns if col not in [diabetes_col, gender_col] + special_cols_log_scale]\n","for col_name in other_cols:\n","    original_values = data_df[col_name].values.reshape(-1, 1)\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    scaled_values = scaler.fit_transform(original_values)\n","    processed_data_parts.append(scaled_values)\n","    scalers_dict[col_name] = {'scaler': scaler, 'log_applied': False, 'original_min': original_values.min(), 'original_max': original_values.max()}\n","    column_info_for_generator_output.append({'name': col_name, 'type': 'scaled_continuous_sigmoid'})\n","    print(f\"Preprocesado {col_name} con MinMaxScaler. Shape: {scaled_values.shape}\")\n","\n","X_train_processed_np = np.concatenate(processed_data_parts, axis=1).astype(np.float32)\n","DATA_DIM = X_train_processed_np.shape[1]\n","print(f\"Forma final de los datos procesados (X_train_processed_np): {X_train_processed_np.shape}\")\n","\n","# Convertir datos a tensores de PyTorch\n","X_train_tensor = torch.tensor(X_train_processed_np, dtype=torch.float32).to(device)\n","\n","\n","# --- 3. Definir el modelo GAN (PyTorch) ---\n","\n","class Generator(nn.Module):\n","    def __init__(self, latent_dim, data_dim):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(latent_dim, 512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.4),\n","            nn.BatchNorm1d(512, momentum=0.8),\n","            nn.Linear(512, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.3),\n","            nn.BatchNorm1d(1024, momentum=0.8),\n","            nn.Linear(1024, 2048),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(2048, momentum=0.8),\n","            nn.Linear(2048, 4096),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.1),\n","            nn.BatchNorm1d(4096, momentum=0.8),\n","            nn.Linear(4096, data_dim),\n","            nn.Sigmoid() # Salida general en [0,1]\n","        )\n","\n","    def forward(self, z):\n","        return self.model(z)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, data_dim):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(data_dim, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 1),\n","            nn.Sigmoid() # Salida binaria (real/falso)\n","        )\n","\n","    def forward(self, img):\n","        return self.model(img)\n","\n","# Inicializar generador y discriminador\n","generator = Generator(LATENT_DIM, DATA_DIM).to(device)\n","discriminator = Discriminator(DATA_DIM).to(device)\n","\n","# Load models\n","#generator.load_state_dict(torch.load(generator_path, map_location=device))\n","#discriminator.load_state_dict(torch.load(discriminator_path, map_location=device))\n","\n","# Función de pérdida\n","adversarial_loss = nn.BCELoss().to(device)\n","\n","# Optimizadores\n","optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE_G, betas=(BETA1, 0.999))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE_D, betas=(BETA1, 0.999))\n","\n","print(\"\\n--- Arquitectura del Generador (PyTorch) ---\")\n","print(generator)\n","print(\"\\n--- Arquitectura del Discriminador (PyTorch) ---\")\n","print(discriminator)\n","\n","\n","# --- 4. Bucle de Entrenamiento (PyTorch) ---\n","print(\"\\nIniciando entrenamiento de la GAN con PyTorch...\")\n","d_loss_history = []\n","g_loss_history = []\n","d_acc_history = [] # Para la precisión del discriminador\n","\n","for epoch in range(EPOCHS):\n","    perm = torch.randperm(X_train_tensor.size(0))\n","    X_train_shuffled = X_train_tensor[perm]\n","\n","    d_loss_epoch = 0\n","    g_loss_epoch = 0\n","    num_batches = X_train_shuffled.size(0) // BATCH_SIZE\n","    for i in range(num_batches): # Iterar sobre batches\n","        # ---------------------\n","        #  Entrenar Discriminador\n","        # ---------------------\n","        discriminator.train()\n","        generator.eval() # Generador en modo evaluación para no actualizar sus BN stats aquí\n","\n","        # Datos reales\n","        real_imgs = X_train_shuffled[i*BATCH_SIZE:(i+1)*BATCH_SIZE].to(device)\n","        real_imgs += 0.1 * torch.randn_like(real_imgs)\n","        real_labels = torch.full((real_imgs.size(0), 1), 0.9, device=device)\n","        #real_labels = torch.ones(real_imgs.size(0), 1, dtype=torch.float32).to(device)\n","\n","        # Datos falsos\n","        noise = torch.randn(real_imgs.size(0), LATENT_DIM, dtype=torch.float32).to(device)\n","        fake_imgs = generator(noise)\n","        fake_imgs += 0.1 * torch.randn_like(fake_imgs)\n","        fake_labels = torch.full((fake_imgs.size(0), 1), 0.1, device=device)\n","        #fake_labels = torch.zeros(real_imgs.size(0), 1, dtype=torch.float32).to(device)\n","\n","        # Entrenar con datos reales\n","        optimizer_D.zero_grad()\n","        real_output = discriminator(real_imgs)\n","        d_loss_real = adversarial_loss(real_output, real_labels)\n","\n","        # Entrenar con datos falsos\n","        fake_output = discriminator(fake_imgs.detach()) # .detach() para no calcular gradientes para G aquí\n","        d_loss_fake = adversarial_loss(fake_output, fake_labels)\n","\n","        d_loss = (d_loss_real + d_loss_fake) / 2\n","        d_loss_epoch += d_loss.item()\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        # Calcular precisión del discriminador (opcional)\n","        # d_accuracy = ((real_output > 0.5).float().sum() + (fake_output < 0.5).float().sum()) / (2 * real_imgs.size(0))\n","\n","\n","        # ---------------------\n","        #  Entrenar Generador\n","        # ---------------------\n","        for _ in range(4):\n","          generator.train() # Generador en modo entrenamiento\n","          optimizer_G.zero_grad()\n","\n","          # Generar datos falsos (nuevo batch de ruido)\n","          noise_g = torch.randn(BATCH_SIZE, LATENT_DIM, dtype=torch.float32).to(device) # Usar BATCH_SIZE fijo para G\n","          gen_imgs_for_g = generator(noise_g)\n","\n","          # Queremos que el discriminador piense que estos son reales\n","          # (usamos real_labels que son todos unos)\n","          # Asegurarse que real_labels_for_g tenga el tamaño correcto si BATCH_SIZE es diferente al último batch de D\n","          real_labels_for_g = torch.ones(gen_imgs_for_g.size(0), 1, dtype=torch.float32).to(device)\n","\n","          output_g = discriminator(gen_imgs_for_g)\n","          g_loss = adversarial_loss(output_g, real_labels_for_g)\n","          g_loss_epoch += g_loss.item()\n","          g_loss.backward()\n","          optimizer_G.step()\n","\n","    # Guardar el progreso al final de la época (promedio si se quiere)\n","    d_loss_history.append(d_loss_epoch / num_batches)\n","    g_loss_history.append(g_loss_epoch / (num_batches*4))\n","    # d_acc_history.append(d_accuracy.item())\n","\n","\n","    if (epoch + 1) % SAMPLE_INTERVAL == 0:\n","        # print(f\"{epoch + 1}/{EPOCHS} [D loss: {d_loss.item():.4f}, acc.: {d_accuracy.item()*100:.2f}%] [G loss: {g_loss.item():.4f}]\")\n","        print(f\"{epoch + 1}/{EPOCHS} [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n","        # Opcional: Generar y guardar una muestra de datos\n","        # generator.eval()\n","        # with torch.no_grad():\n","        #     noise_sample = torch.randn(5, LATENT_DIM, dtype=torch.float32).to(device)\n","        #     generated_sample_scaled = generator(noise_sample).cpu().numpy()\n","        #     print(\"Generated sample (scaled, PyTorch): \\n\", generated_sample_scaled[:2])\n","        # generator.train()\n","\n","# --- Guardar modelos entrenados ---\n","\n","torch.save(generator.state_dict(), generator_path)\n","torch.save(discriminator.state_dict(), discriminator_path)\n","\n","print(f\"Modelos guardados en '{generator_path}' y '{discriminator_path}'\")\n","\n","# --- Graficar historial de pérdidas ---\n","plt.figure(figsize=(10, 5))\n","plt.plot(d_loss_history, label='Discriminator Loss')\n","plt.plot(g_loss_history, label='Generator Loss')\n","plt.title(\"Historial de Pérdidas de la GAN (PyTorch)\")\n","plt.xlabel(\"Época\")\n","plt.ylabel(\"Pérdida\")\n","plt.legend()\n","plt.savefig(f'/content/gdrive/My Drive/ResultCSV/Binary/gan_loss_history_pytorch_{EPOCHS}_{iteration}.png')\n","plt.show()\n","\n","\n","# --- 5. Generación y Postprocesamiento de Datos Finales (PyTorch) ---\n","print(\"\\nGenerando datos sintéticos finales con PyTorch...\")\n","#num_samples_to_generate = 1000 # Esto determina la cantidad de datos sintéticos a generar broders\n","num_samples_per_class = 50000  # Number of samples you want for each class\n","num_classes = data_df['diabetes'].nunique()\n","total_samples_needed = num_samples_per_class * num_classes\n","extra_factor = 10\n","\n","generator.eval() # Modo evaluación\n","synthetic_df_final = pd.DataFrame()\n","all_generated_data_scaled = []\n","generation_batch_size = 512\n","\n","num_to_generate = total_samples_needed * extra_factor\n","\n","# Generar en batches si num_samples_to_generate es muy grande para evitar OOM\n","with torch.no_grad():\n","    for i in range(0, num_to_generate, generation_batch_size):\n","        current_batch_size = min(generation_batch_size, num_to_generate - i)\n","        if current_batch_size <= 0:\n","            break\n","        noise_final_batch = torch.randn(current_batch_size, LATENT_DIM, dtype=torch.float32).to(device)\n","        generated_batch_scaled = generator(noise_final_batch).cpu().numpy()\n","        all_generated_data_scaled.append(generated_batch_scaled)\n","\n","generated_data_scaled_final_np = np.concatenate(all_generated_data_scaled, axis=0)\n","\n","\n","current_col_idx_in_generated = 0\n","for col_info in column_info_for_generator_output:\n","    col_name = col_info['name']\n","    col_type = col_info['type']\n","\n","    if col_type == 'one_hot':\n","        num_classes_other = col_info['num_classes'] #originally num_classes\n","        one_hot_part = generated_data_scaled_final_np[:, current_col_idx_in_generated : current_col_idx_in_generated + num_classes_other]\n","        decoded_classes = np.argmax(one_hot_part, axis=1)\n","        synthetic_df_final[col_name] = decoded_classes\n","        # Si 'Gender' o 'diabetes', mapear de nuevo a sus etiquetas originales si es necesario para la visualización/guardado\n","        if col_name == 'smoking_historyS': ####################################################################\n","            # Invertir el mapeo {'N': 0, 'P': 1, 'Y': 2}\n","            reverse_class_mapping = {v: k for k, v in smoking_mapping.items()}\n","            synthetic_df_final[col_name] = synthetic_df_final[col_name].map(reverse_class_mapping)\n","        elif col_name == 'gender':\n","            # Invertir el mapeo {'F': 0, 'M': 1}\n","            reverse_gender_mapping = {0: 'Female', 1: 'Male', 2: 'Other'}\n","            synthetic_df_final[col_name] = synthetic_df_final[col_name].map(reverse_gender_mapping)\n","        current_col_idx_in_generated += num_classes_other\n","\n","    elif col_type == 'scaled_continuous_sigmoid':\n","        generated_values_scaled = generated_data_scaled_final_np[:, current_col_idx_in_generated : current_col_idx_in_generated + 1]\n","        current_col_idx_in_generated += 1\n","\n","        s_info = scalers_dict[col_name]\n","        scaler_obj = s_info['scaler']\n","        inverted_values = scaler_obj.inverse_transform(generated_values_scaled)\n","\n","        if s_info['log_applied']:\n","            inverted_values = np.expm1(inverted_values)\n","        if data_df[col_name].dtype == 'int64' or (data_df[col_name].dtype == 'float64' and np.all(data_df[col_name] == data_df[col_name].astype(int))):\n","            final_values = np.round(inverted_values)\n","        else:\n","            final_values = inverted_values\n","\n","        final_values = np.clip(final_values, s_info['original_min'], s_info['original_max'])\n","        synthetic_df_final[col_name] = final_values.flatten().astype(data_df[col_name].dtype)\n","\n","synthetic_df_final = synthetic_df_final[original_columns]\n","\n","balanced_synthetic = []\n","\n","for class_value in range(num_classes):\n","    class_samples = synthetic_df_final[synthetic_df_final['diabetes'] == class_value]\n","    balanced_synthetic.append(class_samples.sample(n=num_samples_per_class, replace=True, random_state=42))\n","synthetic_df_final_balanced = pd.concat(balanced_synthetic).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","output_file_pytorch = f'/content/gdrive/My Drive/ResultCSV/Binary/generated_data_gan_pytorch_{EPOCHS}_{iteration}.csv'\n","synthetic_df_final_balanced.to_csv(output_file_pytorch, index=False)\n","print(f\"\\nDatos sintéticos generados y guardados en: {output_file_pytorch}\")\n","\n","# --- Mostrar algunas estadísticas de los datos generados (igual que antes) ---\n","print(\"\\n--- Descripción de los datos originales: ---\")\n","print(data_df.describe())\n","print(\"\\n--- Descripción de los datos sintéticos (PyTorch): ---\")\n","print(synthetic_df_final_balanced.describe())\n","\n","print(\"\\n--- Conteo de valores para CLASS (Original): ---\")\n","print(data_df['diabetes'].value_counts(normalize=True).sort_index())\n","print(\"\\n--- Conteo de valores para CLASS (Sintético - PyTorch): ---\")\n","print(synthetic_df_final_balanced['diabetes'].value_counts(normalize=True).sort_index())\n","\n","fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n","sns.histplot(data_df['age'], ax=axes[0], color='blue', label='Original', kde=True, stat=\"density\")\n","sns.histplot(synthetic_df_final_balanced['age'], ax=axes[0], color='green', label='Sintético (PyTorch)', kde=True, stat=\"density\")\n","axes[0].set_title('Distribución de age')\n","axes[0].legend()\n","\n","sns.histplot(data_df['bmi'], ax=axes[1], color='blue', label='Original', kde=True, stat=\"density\")\n","sns.histplot(synthetic_df_final_balanced['bmi'], ax=axes[1], color='green', label='Sintético (PyTorch)', kde=True, stat=\"density\")\n","axes[1].set_title('Distribución de bmi')\n","axes[1].legend()\n","\n","sns.histplot(data_df['blood_glucose_level'], ax=axes[2], color='blue', label='Original', kde=True, stat=\"density\")\n","sns.histplot(synthetic_df_final_balanced['blood_glucose_level'], ax=axes[2], color='green', label='Sintético (PyTorch)', kde=True, stat=\"density\")\n","axes[2].set_title('Distribución de blood_glucose_level')\n","axes[2].legend()\n","\n","plt.tight_layout()\n","plt.savefig(f'/content/gdrive/My Drive/ResultCSV/Binary/generated_data_distributions_comparison_pytorch_{EPOCHS}_{iteration}.png')\n","plt.show()\n","\n","print(\"\\nFinalizado con PyTorch.\")"]},{"cell_type":"code","execution_count":null,"id":"TLKz4yruCDHt","metadata":{"id":"TLKz4yruCDHt"},"outputs":[],"source":["# --- Función para comparar y visualizar distribuciones ---\n","def compare_data_distributions(real_df, generated_df, numerical_cols, categorical_cols, output_prefix=\"comparison\"):\n","    print(\"\\n--- Iniciando comparación de distribuciones (Reales vs. Sintéticas) ---\")\n","\n","    # 1. Comparación de Estadísticas Descriptivas Generales\n","    print(\"\\n--- Estadísticas Descriptivas - Datos Originales (después de SMOTE) ---\")\n","    print(real_df.describe())\n","    print(\"\\n--- Estadísticas Descriptivas - Datos Sintéticos ---\")\n","    print(generated_df.describe())\n","\n","    # 2. Comparación de Conteo de Valores (para Categóricas) y Varianzas (para Numéricas)\n","    print(\"\\n--- Conteo de Clases / Valores (Categóricas) ---\")\n","    for col in categorical_cols:\n","        print(f\"\\nColumna: {col}\")\n","        print(\"Real:\")\n","        print(real_df[col].value_counts(normalize=True).sort_index())\n","        print(\"Sintético:\")\n","        print(generated_df[col].value_counts(normalize=True).sort_index())\n","\n","    print(\"\\n--- Varianzas de Columnas Numéricas ---\")\n","    real_variances = real_df[numerical_cols].var()\n","    gen_variances = generated_df[numerical_cols].var()\n","    comparison_variances = pd.DataFrame({'Real_Variance': real_variances, 'Synthetic_Variance': gen_variances})\n","    print(comparison_variances)\n","\n","    # 3. Visualización de Histogramas/KDE (para Numéricas)\n","    print(\"\\n--- Visualizando distribuciones numéricas ---\")\n","    num_plots_per_row = 3\n","    num_rows_numerical = (len(numerical_cols) + num_plots_per_row - 1) // num_plots_per_row\n","    fig_num, axes_num = plt.subplots(num_rows_numerical, num_plots_per_row, figsize=(5 * num_plots_per_row, 4 * num_rows_numerical))\n","    axes_num = axes_num.flatten() # Para manejar subplots en 1D o 2D\n","\n","    for i, col in enumerate(numerical_cols):\n","        sns.histplot(real_df[col], ax=axes_num[i], color='blue', label='Real', kde=True, stat=\"density\", alpha=0.6)\n","        sns.histplot(generated_df[col], ax=axes_num[i], color='green', label='Sintético', kde=True, stat=\"density\", alpha=0.6)\n","        axes_num[i].set_title(f'Distribución de {col}')\n","        axes_num[i].legend()\n","\n","    # Ocultar ejes vacíos si hay menos subplots que el espacio total\n","    for j in range(i + 1, len(axes_num)):\n","        fig_num.delaxes(axes_num[j])\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"{output_prefix}_numerical_distributions.png\")\n","    plt.show()\n","\n","    # 4. Visualización de Gráficos de Barras (para Categóricas)\n","    print(\"\\n--- Visualizando distribuciones categóricas ---\")\n","    num_plots_per_row = 2\n","    num_rows_categorical = (len(categorical_cols) + num_plots_per_row - 1) // num_plots_per_row\n","    fig_cat, axes_cat = plt.subplots(num_rows_categorical, num_plots_per_row, figsize=(6 * num_plots_per_row, 5 * num_rows_categorical))\n","    axes_cat = axes_cat.flatten()\n","\n","    for i, col in enumerate(categorical_cols):\n","        real_counts = real_df[col].value_counts(normalize=True).sort_index()\n","        gen_counts = generated_df[col].value_counts(normalize=True).sort_index()\n","\n","        # --- LÍNEA CORREGIDA AQUÍ ---\n","        # Usa .union() para obtener todas las categorías únicas de ambos Series de forma robusta\n","        all_categories = real_counts.index.union(gen_counts.index)\n","\n","        df_plot = pd.DataFrame({\n","            'Category': all_categories,\n","            'Real': real_counts.reindex(all_categories, fill_value=0),\n","            'Sintético': gen_counts.reindex(all_categories, fill_value=0)\n","        }).melt(id_vars='Category', var_name='Dataset', value_name='Proportion')\n","\n","        sns.barplot(x='Category', y='Proportion', hue='Dataset', data=df_plot, ax=axes_cat[i], palette={'Real': 'blue', 'Sintético': 'green'})\n","        axes_cat[i].set_title(f'Distribución de {col}')\n","        axes_cat[i].set_ylabel('Proporción')\n","\n","    for j in range(i + 1, len(axes_cat)):\n","        fig_cat.delaxes(axes_cat[j])\n","\n","    plt.tight_layout()\n","    plt.savefig(f\"{output_prefix}_categorical_distributions.png\")\n","    plt.show()\n","\n","    print(\"\\n--- Fin de la comparación de distribuciones ---\")\n","\n","\n","# --- Dónde llamar la función de comparación en tu script ---\n","# Asegúrate de que estas variables estén definidas y contengan tus DataFrames finales:\n","# data_df (tu DataFrame de datos reales/SMOTEd y limpios)\n","# synthetic_df_final_balanced (tu DataFrame de datos generados por la GAN)\n","\n","# Define tus columnas numéricas y categóricas\n","numerical_features_for_comparison = ['age','hypertension','heart_disease','bmi','HbA1c_level','blood_glucose_level','diabetes']\n","categorical_features_for_comparison = ['gender', 'smoking_history']\n","\n","# Llama a la función de comparación\n","compare_data_distributions(\n","    real_df=data_df, # Este es tu DF de datos originales después de SMOTE y limpieza\n","    generated_df=synthetic_df_final_balanced, # Este es tu DF de datos generados por la GAN\n","    numerical_cols=numerical_features_for_comparison,\n","    categorical_cols=categorical_features_for_comparison,\n","    output_prefix=\"gan_data_comparison\" # Prefijo para los nombres de los archivos de imagen\n",")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}